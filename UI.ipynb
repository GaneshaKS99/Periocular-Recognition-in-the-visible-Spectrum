{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UI.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKWkEJ4R49c_"
      },
      "source": [
        "#Install ngrok for flask based web app\n",
        "!pip install flask-ngrok\n",
        "#Mounting Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uytGIpmj4_CA"
      },
      "source": [
        "#Importing Required Modules\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import imutils\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import math\n",
        "from tensorflow.keras.preprocessing import image as IMAGE\n",
        "from google.colab.patches import cv2_imshow\n",
        "from imutils import face_utils\n",
        "import dlib\n",
        "import keras\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pickle\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask\n",
        "from flask import render_template, request, jsonify\n",
        "from sklearn.metrics import accuracy_score\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "#Face Detection Model Initialization\n",
        "prototxt = '/content/drive/My Drive/dataset1/models/deploy.prototxt'\n",
        "dnn_path = '/content/drive/My Drive/dataset1/models/res10_300x300_ssd_iter_140000.caffemodel'\n",
        "face_detection_model = cv2.dnn.readNetFromCaffe(prototxt, dnn_path)\n",
        "\n",
        "#Facial Landmarks Detector Model\n",
        "model_path = '/content/drive/My Drive/dataset1/models/shape_predictor_5_face_landmarks.dat'\n",
        "predictor = dlib.shape_predictor(model_path)\n",
        "\n",
        "#Path for directories from the Database\n",
        "train_dir = '/content/drive/My Drive/dataset1/trainset'\n",
        "roi_dir = '/content/drive/My Drive/dataset1/roiset'\n",
        "clahe_dir = '/content/drive/My Drive/dataset1/claheset'\n",
        "test_dir = '/content/drive/My Drive/dataset1/testset'\n",
        "aug_dir = '/content/drive/My Drive/dataset1/augmentset'\n",
        "test_roi_dir = '/content/drive/My Drive/dataset1/testroiset'\n",
        "test_clahe_dir = '/content/drive/My Drive/dataset1/testclaheset'\n",
        "val_dir = '/content/drive/My Drive/dataset1/valset'\n",
        "\n",
        "#Test Subjects Names\n",
        "people_in_db = {\n",
        "  \"akshay_nawalkha\": \"Akshay Nawalkha\",\n",
        "  \"akshay_r\": \"Akshay R\",\n",
        "  \"andrew\": \"Andrew\",\n",
        "  \"animesh_r\": \"Animesh R\",\n",
        "  \"arjun\": \"Arjun\",\n",
        "  \"faiza_ahmed\": \"Faiza Ahmed\",\n",
        "  \"hemang_bhardwaj\": \"Hemang Bhardwaj\",\n",
        "  \"jacob_w\": \"Jacob W\",\n",
        "  \"k_sujan_chowdary\": \"K Sujan Chowdary\",\n",
        "  \"kanchi_k\": \"Kanchi K\",\n",
        "  \"kumar_shantanu_khare\": \"Kumar Shantanu Khare\",\n",
        "  \"pranav_nawalkha\": \"Pranav Nawalkha\",\n",
        "  \"saumil_b\": \"Saumil B\",\n",
        "  \"sricharan\": \"Sricharan\",\n",
        "  \"sharan\": \"Sharan\",\n",
        "  \"shashank\": \"Shashank\",\n",
        "  \"shreyas_s\": \"Shreyas S\",\n",
        "  \"sphurthy\": \"Sphurthy\",\n",
        "  \"srujan_d\": \"Srujan D\",\n",
        "  \"srujana_golla\": \"Srujana Golla\",\n",
        "  \"suma_rao\": \"Suma Rao\",\n",
        "  \"swapneel_r\": \"Swapneel R\",\n",
        "  \"uday_kasturi\":\"Uday Kasturi\",\n",
        "  \"yash_a\": \"Yash A\" \n",
        "}\n",
        "\n",
        "#a and b values for changing extent of region of interest\n",
        "a = 1.25\n",
        "b = 0.95\n",
        "\n",
        "#Augementor for expanding training Data\n",
        "augmentor = ImageDataGenerator(\n",
        "\t\trotation_range=20,\n",
        "\t\twidth_shift_range=0.2,\n",
        "\t\theight_shift_range=0.2,\n",
        "\t\tshear_range=0.15,\n",
        "\t\tvertical_flip=True,\n",
        "    brightness_range=[0.5,1.5],\n",
        "    zoom_range = 0.3, \n",
        "\t\tfill_mode=\"nearest\")\n",
        "\n",
        "#VGG16 Feature extractor\n",
        "vggmodel = VGG16(weights='imagenet', include_top=False)\n",
        "#KNN Classifiers\n",
        "left_model = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
        "right_model = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
        "#Dictionaries to calculate avg sum of recognition probabilities\n",
        "classes_prob_left = {}\n",
        "classes_prob_right = {}\n",
        "avg_prob = {}\n",
        "\n",
        "def augmentation(train_dir):\n",
        "  temp = 0\n",
        "  for person in os.listdir(train_dir):\n",
        "    person_dir = os.path.join(train_dir, person)\n",
        "    save_dir = os.path.join(aug_dir,person)\n",
        "    for img in os.listdir(person_dir):\n",
        "      print(\"augmentation on \" + person)\n",
        "      img_path=os.path.join(person_dir, img)\n",
        "      to_augment = load_img(img_path)\n",
        "      to_augment = img_to_array(to_augment)\n",
        "      to_augment = np.expand_dims(to_augment, axis=0)\n",
        "      total_images = 0\n",
        "      generator = augmentor.flow(to_augment, batch_size=1, save_to_dir=save_dir, save_prefix=person, save_format=\"jpg\")\n",
        "      for to_augment in generator:\n",
        "\t      total_images += 1\n",
        "\t      if total_images == 10:\n",
        "\t\t      break\n",
        "  print(\"STEP 1: DATA AUGMENTATION DONE !!!\")\n",
        "\n",
        "#Detect Face region using DNN\n",
        "def get_face(image, model):\n",
        "  h, w = image.shape[:2]\n",
        "  blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
        "  model.setInput(blob)\n",
        "  detected_face = model.forward()\n",
        "  for i in range(detected_face.shape[2]):\n",
        "    confidence = detected_face[0, 0, i, 2]\n",
        "    if confidence > 0.5:\n",
        "      box = detected_face[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "      (x, y, x1, y1) = box.astype(\"int\")\n",
        "      face = [x, y, x1, y1]\n",
        "    return face\n",
        "\n",
        "#Convert face region bounding box to square for consistency\n",
        "def get_square_face(image, face):\n",
        "  offset = int(abs((face[3] - face[1]) * 0.1))\n",
        "  offset_arr = [0, offset]\n",
        "  left_x = face[0] + offset_arr[0]\n",
        "  top_y = face[1] + offset_arr[1]\n",
        "  right_x = face[2] + offset_arr[0]\n",
        "  bottom_y = face[3] + offset_arr[1]\n",
        "  shifted_box = [left_x, top_y, right_x, bottom_y]\n",
        "  bb_width = right_x - left_x\n",
        "  bb_height = bottom_y - top_y\n",
        "  diff = bb_height - bb_width\n",
        "  delta = int(abs(diff) / 2)\n",
        "  if diff == 0:\n",
        "    pass\n",
        "  elif diff > 0:\n",
        "    left_x -= delta\n",
        "    right_x += delta\n",
        "    if diff % 2 == 1:\n",
        "      right_x += 1\n",
        "  else:\n",
        "    top_y -= delta\n",
        "    bottom_y += delta\n",
        "    if diff % 2 == 1:\n",
        "      bottom_y += 1\n",
        "  assert ((right_x - left_x) == (bottom_y - top_y)), 'Box is not square.'\n",
        "  facebox = [left_x, top_y, right_x, bottom_y]\n",
        "  h, w = image.shape[:2]\n",
        "  if facebox[0] < 0:\n",
        "    facebox[0] = 0\n",
        "  if facebox[1] < 0:\n",
        "    facebox[1] = 0\n",
        "  if facebox[2] > w:\n",
        "    facebox[2] = w\n",
        "  if facebox[3] > h:\n",
        "    facebox[3] = h\n",
        "  face_img = image[facebox[1]: facebox[3], facebox[0]: facebox[2]]\n",
        "  face_img = cv2.resize(face_img, (128, 128))\n",
        "  face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
        "  return facebox\n",
        "\n",
        "def euclidean_dist(x, y):\n",
        "  distance = 0.0\n",
        "  for i in range(len(x)-1):\n",
        "    distance += (abs(x[i] - y[i]))**2\n",
        "  return math.sqrt(distance)\n",
        "\n",
        "def roi_extraction(directory):\n",
        "  l_outer = 37\n",
        "  l_inner = 40\n",
        "  r_outer = 46\n",
        "  r_inner = 43\n",
        "  canthus_attr=[37,40,43,46]\n",
        "  person_id = 1\n",
        "  total_people = 24\n",
        "  for person in os.listdir(directory):\n",
        "    person_dir = os.path.join(directory, person)\n",
        "    print(str(person_id) + \" of \" + str(total_people) + \": PERFORMING ROI EXTRACTION ON\", people_in_db[person])\n",
        "    for picture in os.listdir(person_dir):\n",
        "      img_path=os.path.join(person_dir, picture)\n",
        "      img = cv2.imread(img_path)\n",
        "      img = imutils.resize(img, width=400)\n",
        "      img_copy = img.copy()\n",
        "      img_copy2 = img.copy()\n",
        "      img_copy3 = img.copy()\n",
        "      face = get_face(img, face_detection_model)\n",
        "      facebox = get_square_face(img, face)\n",
        "      #cv2.rectangle(img_copy, (facebox[0], facebox[1]),(facebox[2],facebox[3]), (0,0,255),2)\n",
        "      #print(\"DETECTED FACE REGION\\n\")\n",
        "      #cv2_imshow(img_copy)\n",
        "      #print(\"\\n\\n\\n\")\n",
        "      facebox = dlib.rectangle(facebox[0],facebox[1],facebox[2],facebox[3])\n",
        "      shape = predictor(img, facebox)\n",
        "      shape = face_utils.shape_to_np(shape)\n",
        "      for (i, (x, y)) in enumerate(shape):\n",
        "        if i == 4 :\n",
        "          pass\n",
        "        else:\n",
        "          cv2.circle(img_copy2, (x, y), 1, (0, 0, 255), 2)\n",
        "      #print(\"DETECTED FACIAL LANDMARKS\")\n",
        "      #cv2_imshow(img_copy2)\n",
        "      #print(\"\\n\\n\\n\")\n",
        "      D_left = euclidean_dist(shape[3], shape[2])\n",
        "      D_right = euclidean_dist(shape[0], shape[1])\n",
        "      Lpx = (shape[2][0] + shape[3][0])/2\n",
        "      Lpy = (shape[2][1] + shape[3][1])/2\n",
        "      Rpx = (shape[0][0] + shape[1][0])/2\n",
        "      Rpy = (shape[0][1] + shape[1][1])/2\n",
        "      tlc_left = (int(Lpx - a * D_left) , int(Lpy - b * D_left))\n",
        "      brc_left = (int(Lpx + a * D_left) , int(Lpy + b * D_left))\n",
        "      tlc_right = (int(Rpx - a * D_right) , int(Rpy - b * D_right))\n",
        "      brc_right = (int(Rpx + a * D_right) , int(Rpy + b * D_right))\n",
        "      cv2.rectangle(img_copy3, tlc_left, brc_left, (0, 255, 0), 2)\n",
        "      cropped_left = img[tlc_left[1]:brc_left[1], tlc_left[0]:brc_left[0]]\n",
        "      #cv2.rectangle(img_copy3, tlc_right, brc_right, (0, 255, 0), 2)\n",
        "      #print(\"DETECTED PERIOCULAR REGIONS\")\n",
        "      #cv2_imshow(img_copy3)\n",
        "      #print(\"\\n\\n\\n\")\n",
        "      cropped_right = img[tlc_right[1]:brc_right[1], tlc_right[0]:brc_right[0]]\n",
        "      cropped_left = img[tlc_left[1]:brc_left[1], tlc_left[0]:brc_left[0]]\n",
        "      #print(\"CROPPED PERIOCULAR REGIONS\")\n",
        "      #cv2_imshow(cropped_right)\n",
        "      #cv2_imshow(cropped_left)\n",
        "      #print(\"\\n\\n\\n\")\n",
        "      cropped_name_left = \"left_\" + picture\n",
        "      cropped_name_right = \"right_\" + picture\n",
        "      cropped_path = os.path.join(roi_dir, person)\n",
        "      cropped_path_left = os.path.join(cropped_path, \"left\")\n",
        "      cropped_path_right = os.path.join(cropped_path, \"right\")\n",
        "      cropped_path_left = os.path.join(cropped_path_left, cropped_name_left)\n",
        "      cropped_path_right = os.path.join(cropped_path_right, cropped_name_right)\n",
        "      #print(cropped_path_left, cropped_path_right)\n",
        "      cv2.imwrite (cropped_path_left, cropped_left)\n",
        "      cv2.imwrite (cropped_path_right, cropped_right)\n",
        "    person_id+=1      \n",
        "  print(\"STEP 1 of 3: ROI EXTRACTION COMPLETED\\n\")\n",
        "\n",
        "def clahe_eye(directory, left_right, person):\n",
        "  for picture in os.listdir(directory):\n",
        "    img_path=os.path.join(directory, picture)\n",
        "    img = cv2.imread(img_path)\n",
        "    #cv2_imshow(picture)\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    h,s,v = cv2.split(hsv)\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(4, 4))\n",
        "    v = clahe.apply(v)\n",
        "    hsv = cv2.merge([h,s,v])\n",
        "    clahe_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "    #print(\"CLAHE PERFORMED\\n\")\n",
        "    #cv2_imshow(clahe_image)\n",
        "    #print(\"\\n\\n\\n\")\n",
        "    clahe_name = 'clahe_' + picture\n",
        "    clahe_path = os.path.join(clahe_dir, person)\n",
        "    if left_right == 0:\n",
        "      clahe_path = os.path.join(clahe_path,\"left\")\n",
        "    else:\n",
        "      clahe_path = os.path.join(clahe_path,\"right\")\n",
        "    clahe_path = os.path.join(clahe_path,clahe_name)\n",
        "    #print(clahe_path)\n",
        "    cv2.imwrite(clahe_path,clahe_image)\n",
        "\n",
        "def clahe_preprocessing(directory):\n",
        "  person_id = 1\n",
        "  total_people = 24\n",
        "  for person in os.listdir(directory):\n",
        "    print(str(person_id) + \" of \" + str(total_people) + \": PERFORMING CLAHE PRE-PROCESSING ON\", people_in_db[person])\n",
        "    person_dir = os.path.join(roi_dir, person)\n",
        "    person_dir_left = os.path.join(person_dir, \"left\")\n",
        "    person_dir_right = os.path.join(person_dir, \"right\")\n",
        "    clahe_eye(person_dir_left, 0, person)\n",
        "    clahe_eye(person_dir_right, 1, person)\n",
        "    person_id+=1\n",
        "  print(\"STEP 2 of 3: CLAHE PRE-PROCESSING COMPLETED\")\n",
        "\n",
        "def train_classifier():\n",
        "  all_features_left = []\n",
        "  all_features_right = []\n",
        "  labels_left = []\n",
        "  labels_right = []\n",
        "  person_id = 1\n",
        "  total_people = 24\n",
        "  for person in os.listdir(clahe_dir):\n",
        "    print(str(person_id) + \" of \" + str(total_people) + \": TRAINING ON\", people_in_db[person])\n",
        "    person_dir = os.path.join(clahe_dir, person)\n",
        "    person_dir_left = os.path.join(person_dir, \"left\")\n",
        "    person_dir_right = os.path.join(person_dir, \"right\")\n",
        "    for picture in os.listdir(person_dir_left):\n",
        "      label = person + \"_left\"\n",
        "      img_path=os.path.join(person_dir_left, picture)\n",
        "      #print(img_path)\n",
        "      img = IMAGE.load_img(img_path, target_size=(224, 224))\n",
        "      img_arr = IMAGE.img_to_array(img)\n",
        "      img_arr = np.expand_dims(img_arr, axis=0)\n",
        "      img_arr = preprocess_input(img_arr)\n",
        "      feature_vector = vggmodel.predict(img_arr)\n",
        "      #print(features)\n",
        "      vgg16_feature_np = np.array(feature_vector)\n",
        "      vgg16_feature_np = vgg16_feature_np.flatten()\n",
        "      all_features_left.append(vgg16_feature_np)\n",
        "      labels_left.append(label)\n",
        "    for picture in os.listdir(person_dir_right):\n",
        "      label = person + \"_right\"\n",
        "      img_path=os.path.join(person_dir_right, picture)\n",
        "      #print(img_path)\n",
        "      img = IMAGE.load_img(img_path, target_size=(224, 224))\n",
        "      img_arr = IMAGE.img_to_array(img)\n",
        "      img_arr = np.expand_dims(img_arr, axis=0)\n",
        "      img_arr = preprocess_input(img_arr)\n",
        "      feature_vector = vggmodel.predict(img_arr)\n",
        "      #print(features)\n",
        "      vgg16_feature_np = np.array(feature_vector)\n",
        "      vgg16_feature_np = vgg16_feature_np.flatten()\n",
        "      all_features_right.append(vgg16_feature_np)\n",
        "      labels_right.append(label)\n",
        "    person_id+=1\n",
        "  left_model.fit(all_features_left, labels_left)\n",
        "  right_model.fit(all_features_right, labels_right)\n",
        "  print(\"STEP 3 of 3: TRAINING MODEL COMPLETED\")\n",
        "\n",
        "def create_model():\n",
        "  roi_extraction(train_dir)\n",
        "  clahe_preprocessing(roi_dir)\n",
        "  train_classifier()\n",
        "  pickle.dump(left_model, open('/content/drive/My Drive/dataset1/models/left.sav', 'wb'))\n",
        "  pickle.dump(right_model, open('/content/drive/My Drive/dataset1/models/right.sav', 'wb'))\n",
        "  return \"done\"\n",
        "\n",
        "def roi_extraction_test(img_path):\n",
        "  picture = \"1.jpg\"\n",
        "  l_outer = 37\n",
        "  l_inner = 40\n",
        "  r_outer = 46\n",
        "  r_inner = 43\n",
        "  canthus_attr=[37,40,43,46]\n",
        "  img = cv2.imread(img_path)\n",
        "  img = imutils.resize(img, width=400)\n",
        "  #cv2_imshow(img)\n",
        "  img_copy = img.copy()\n",
        "  img_copy2 = img.copy()\n",
        "  img_copy3 = img.copy()\n",
        "  face = get_face(img, face_detection_model)\n",
        "  print(face)\n",
        "  if face == None:\n",
        "    print(\"NO FACE SEEN\")\n",
        "  facebox = get_square_face(img, face)\n",
        "  cv2.rectangle(img_copy, (facebox[0], facebox[1]),(facebox[2],facebox[3]), (0,0,255),2)\n",
        "  print(\"DETECTED FACE REGION\\n\")\n",
        "  cv2_imshow(img_copy)\n",
        "  print(\"\\n\\n\\n\")\n",
        "  facebox = dlib.rectangle(facebox[0],facebox[1],facebox[2],facebox[3])\n",
        "  shape = predictor(img, facebox)\n",
        "  shape = face_utils.shape_to_np(shape)\n",
        "  for (i, (x, y)) in enumerate(shape):\n",
        "    if i == 4 :\n",
        "      pass\n",
        "    else:\n",
        "      cv2.circle(img_copy, (x, y), 1, (0, 0, 255), 2)\n",
        "  print(\"DETECTED FACIAL LANDMARKS\")\n",
        "  cv2_imshow(img_copy2)\n",
        "  print(\"\\n\\n\\n\")\n",
        "  D_left = euclidean_dist(shape[3], shape[2])\n",
        "  D_right = euclidean_dist(shape[0], shape[1])\n",
        "  Lpx = (shape[2][0] + shape[3][0])/2\n",
        "  Lpy = (shape[2][1] + shape[3][1])/2\n",
        "  Rpx = (shape[0][0] + shape[1][0])/2\n",
        "  Rpy = (shape[0][1] + shape[1][1])/2\n",
        "  tlc_left = (int(Lpx - a * D_left) , int(Lpy - b * D_left))\n",
        "  brc_left = (int(Lpx + a * D_left) , int(Lpy + b * D_left))\n",
        "  tlc_right = (int(Rpx - a * D_right) , int(Rpy - b * D_right))\n",
        "  brc_right = (int(Rpx + a * D_right) , int(Rpy + b * D_right))\n",
        "  cv2.rectangle(img_copy3, tlc_left, brc_left, (0, 255, 0), 2)\n",
        "  cropped_left = img[tlc_left[1]:brc_left[1], tlc_left[0]:brc_left[0]]\n",
        "  cv2.rectangle(img_copy3, tlc_right, brc_right, (0, 255, 0), 2)\n",
        "  print(\"DETECTED PERIOCULAR REGIONS\")\n",
        "  cv2_imshow(img_copy3)\n",
        "  print(\"\\n\\n\\n\")\n",
        "  #cv2_imshow(img_copy2)\n",
        "  cropped_right = img[tlc_right[1]:brc_right[1], tlc_right[0]:brc_right[0]]\n",
        "  cropped_left = img[tlc_left[1]:brc_left[1], tlc_left[0]:brc_left[0]]\n",
        "  print(\"CROPPED PERIOCULAR REGIONS\")\n",
        "  cv2_imshow(cropped_right)\n",
        "  cv2_imshow(cropped_left)\n",
        "  print(\"\\n\\n\\n\")\n",
        "  cropped_name_left = \"left_test_\" + picture\n",
        "  cropped_name_right = \"right_test_\" + picture\n",
        "  cropped_path = test_roi_dir\n",
        "  cropped_path_left = os.path.join(cropped_path, \"left\")\n",
        "  cropped_path_right = os.path.join(cropped_path, \"right\")\n",
        "  cropped_path_left = os.path.join(cropped_path_left, cropped_name_left)\n",
        "  cropped_path_right = os.path.join(cropped_path_right, cropped_name_right)\n",
        "  #print(cropped_path_left, cropped_path_right)\n",
        "  cv2.imwrite (cropped_path_left, cropped_left)\n",
        "  cv2.imwrite (cropped_path_right, cropped_right)\n",
        "\n",
        "def clahe_eye_test(directory, left_right):\n",
        "  for picture in os.listdir(directory):\n",
        "    img_path=os.path.join(directory, picture)\n",
        "    img = cv2.imread(img_path)\n",
        "    #cv2_imshow(picture)\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    h,s,v = cv2.split(hsv)\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(4, 4))\n",
        "    v = clahe.apply(v)\n",
        "    hsv = cv2.merge([h,s,v])\n",
        "    clahe_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "    print(\"CLAHE PERFORMED\\n\")\n",
        "    cv2_imshow(clahe_image)\n",
        "    print(\"\\n\\n\\n\")\n",
        "    #cv2_imshow(clahe_image)\n",
        "    clahe_name = 'testclahe_' + picture\n",
        "    clahe_path = test_clahe_dir\n",
        "    if left_right == 0:\n",
        "      clahe_path = os.path.join(clahe_path,\"left\")\n",
        "    else:\n",
        "      clahe_path = os.path.join(clahe_path,\"right\")\n",
        "    clahe_path = os.path.join(clahe_path,clahe_name)\n",
        "    #print(clahe_path)\n",
        "    cv2.imwrite(clahe_path,clahe_image)\n",
        "\n",
        "def clahe_preprocessing_test(directory):\n",
        "    test_dir_left = os.path.join(directory, \"left\")\n",
        "    test_dir_right = os.path.join(directory, \"right\")\n",
        "    clahe_eye_test(test_dir_left, 0)\n",
        "    clahe_eye_test(test_dir_right, 1)\n",
        "\n",
        "def predict_person(img_path):\n",
        "  loaded_left = pickle.load(open('/content/drive/My Drive/dataset1/models/left.sav', 'rb'))\n",
        "  loaded_right = pickle.load(open('/content/drive/My Drive/dataset1/models/right.sav', 'rb'))\n",
        "  roi_extraction_test(img_path)\n",
        "  clahe_preprocessing_test(test_roi_dir)\n",
        "  test_clahe_dir_left = os.path.join(test_clahe_dir, \"left\")\n",
        "  test_clahe_dir_right = os.path.join(test_clahe_dir, \"right\")\n",
        "  for pic in os.listdir(test_clahe_dir_left):\n",
        "    left_eye_path = os.path.join(test_clahe_dir_left, pic)\n",
        "    left_eye = IMAGE.load_img(left_eye_path, target_size=(224, 224))\n",
        "    img_arr = IMAGE.img_to_array(left_eye)\n",
        "    img_arr = np.expand_dims(img_arr, axis=0)\n",
        "    img_arr = preprocess_input(img_arr)\n",
        "    feature_vec = vggmodel.predict(img_arr)\n",
        "    vgg16_feature_np = np.array(feature_vec)\n",
        "    vgg16_feature_np = vgg16_feature_np.flatten()\n",
        "    rec_left = loaded_left.predict([vgg16_feature_np])\n",
        "    p_pred_left = loaded_left.predict_proba([vgg16_feature_np])\n",
        "    #print(rec_left, p_pred_left)\n",
        "    rec_left = rec_left.tolist()\n",
        "    rec_left = rec_left[0]\n",
        "    person_left = rec_left.replace(\"_left\", \"\")\n",
        "    #print(person_left)\n",
        "  for pic in os.listdir(test_clahe_dir_right):\n",
        "    right_eye_path = os.path.join(test_clahe_dir_right, pic)\n",
        "    right_eye = IMAGE.load_img(right_eye_path, target_size=(224, 224))\n",
        "    img_arr = IMAGE.img_to_array(right_eye)\n",
        "    img_arr = np.expand_dims(img_arr, axis=0)\n",
        "    img_arr = preprocess_input(img_arr)\n",
        "    feature_vec = vggmodel.predict(img_arr)\n",
        "    vgg16_feature_np = np.array(feature_vec)\n",
        "    vgg16_feature_np = vgg16_feature_np.flatten()\n",
        "    rec_right = loaded_right.predict([vgg16_feature_np])\n",
        "    p_pred_right = loaded_right.predict_proba([vgg16_feature_np])\n",
        "    rec_right = rec_right.tolist()\n",
        "    rec_right = rec_right[0]\n",
        "    person_right = rec_right.replace(\"_right\", \"\")\n",
        "    #print(person_right)\n",
        "    #print(rec_right, p_pred_right)\n",
        "  if (person_right == person_left) :\n",
        "    predicted = people_in_db[person_left]\n",
        "    return predicted\n",
        "    #print(\"This is\", people_in_db[person_left])\n",
        "  else :\n",
        "    right_classes = loaded_right.classes_\n",
        "    left_classes = loaded_left.classes_\n",
        "    i = 0\n",
        "    for label in left_classes:\n",
        "      label = label.replace(\"_left\", \"\")\n",
        "      classes_prob_left[label]=p_pred_left[0][i]\n",
        "      i+=1\n",
        "    #print(\"prob left\", classes_prob_left)\n",
        "    i = 0\n",
        "    for label in right_classes:\n",
        "      label = label.replace(\"_right\", \"\")\n",
        "      classes_prob_right[label]=p_pred_right[0][i]\n",
        "      i+=1\n",
        "    #print(\"prob_right\", classes_prob_right)\n",
        "    for pred_label in classes_prob_left:\n",
        "      avg_probability = (classes_prob_left[pred_label] + classes_prob_right[pred_label])/2\n",
        "      avg_prob[pred_label] = avg_probability\n",
        "    #print(\"avg\", avg_prob)\n",
        "    predicted = max(avg_prob, key=avg_prob.get)\n",
        "    predicted = people_in_db[predicted]\n",
        "    return predicted\n",
        "\n",
        "def get_model_accuracy():\n",
        "  true_labels=[]\n",
        "  pred_labels=[]\n",
        "  for person in os.listdir(val_dir):\n",
        "    person_dir = os.path.join(val_dir, person)\n",
        "    for pic in os.listdir(person_dir):\n",
        "      true_labels.append(people_in_db[person])\n",
        "      path = os.path.join(person_dir, pic)\n",
        "      print(person, pic)\n",
        "      predicted_person = predict_person(path)\n",
        "      pred_labels.append(predicted_person)\n",
        "      img = cv2.imread(path)\n",
        "      img = imutils.resize(img, width=100)\n",
        "      print(predicted_person + \"\\n\")\n",
        "      #cv2_imshow(img)\n",
        "      #print(true_labels)\n",
        "      #print(pred_labels)\n",
        "  #print(accuracy_score(true_labels, pred_labels) * 100, \"%\")\n",
        "  return (accuracy_score(true_labels, pred_label) * 100)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}